#!/usr/bin/env python3
"""
è‚¡ç¥¨æ•°æ®ç®¡ç†å™¨

åŠŸèƒ½ï¼š
- æœ¬åœ°ç¼“å­˜å†å²æ•°æ®
- å¢é‡æ›´æ–°ï¼ˆåªè·å–æ–°æ•°æ®ï¼‰
- å¤šæ•°æ®æºæ”¯æŒï¼ˆakshare + baostockï¼‰
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Optional, Dict, List
import warnings
warnings.filterwarnings('ignore')

# æ•°æ®å­˜å‚¨ç›®å½•
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data', 'stocks')
os.makedirs(DATA_DIR, exist_ok=True)


def get_stock_file(symbol: str) -> str:
    """è·å–è‚¡ç¥¨æ•°æ®æ–‡ä»¶è·¯å¾„"""
    return os.path.join(DATA_DIR, f"{symbol}.csv")


def load_local_data(symbol: str) -> Optional[pd.DataFrame]:
    """åŠ è½½æœ¬åœ°ç¼“å­˜æ•°æ®"""
    file_path = get_stock_file(symbol)
    if os.path.exists(file_path):
        try:
            df = pd.read_csv(file_path, index_col=0, parse_dates=True)
            return df
        except Exception as e:
            print(f"åŠ è½½æœ¬åœ°æ•°æ®å¤±è´¥ {symbol}: {e}")
    return None


def save_local_data(symbol: str, df: pd.DataFrame):
    """ä¿å­˜æ•°æ®åˆ°æœ¬åœ°"""
    file_path = get_stock_file(symbol)
    try:
        df.to_csv(file_path)
        print(f"âœ… æ•°æ®å·²ç¼“å­˜: {symbol} ({len(df)}æ¡)")
    except Exception as e:
        print(f"ä¿å­˜æœ¬åœ°æ•°æ®å¤±è´¥ {symbol}: {e}")


def fetch_new_data(symbol: str, days: int = 365) -> Optional[pd.DataFrame]:
    """ä»ç½‘ç»œè·å–æ–°æ•°æ®"""
    try:
        from stock_data import get_stock_daily
        df = get_stock_daily(symbol)
        return df
    except Exception as e:
        print(f"è·å–ç½‘ç»œæ•°æ®å¤±è´¥ {symbol}: {e}")
        return None


def get_stock_data_cached(symbol: str, days: int = 365, force_refresh: bool = False) -> Optional[pd.DataFrame]:
    """
    è·å–è‚¡ç¥¨æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    ç­–ç•¥ï¼š
    1. å…ˆå°è¯•åŠ è½½æœ¬åœ°æ•°æ®
    2. å¦‚æœæœ¬åœ°æ•°æ®è¶…è¿‡7å¤©æ²¡æ›´æ–°ï¼Œåˆ™å¢é‡æ›´æ–°
    3. å¦‚æœæœ¬åœ°æ•°æ®ä¸å­˜åœ¨ï¼Œåˆ™å®Œæ•´ä¸‹è½½
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        days: éœ€è¦çš„å¤©æ•°
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
    
    Returns:
        DataFrame æˆ– None
    """
    local_df = load_local_data(symbol)
    
    # æƒ…å†µ1: å¼ºåˆ¶åˆ·æ–°
    if force_refresh:
        print(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–° {symbol}...")
        df = fetch_new_data(symbol, days)
        if df is not None and len(df) > 0:
            save_local_data(symbol, df)
            return df.tail(days)
        return local_df
    
    # æƒ…å†µ2: æœ¬åœ°æ— æ•°æ®
    if local_df is None or len(local_df) == 0:
        print(f"ğŸ“¥ é¦–æ¬¡ä¸‹è½½ {symbol}...")
        df = fetch_new_data(symbol, days)
        if df is not None and len(df) > 0:
            save_local_data(symbol, df)
            return df.tail(days)
        return None
    
    # æƒ…å†µ3: æ£€æŸ¥æ˜¯å¦éœ€è¦å¢é‡æ›´æ–°
    last_date = local_df.index[-1]
    today = datetime.now()
    days_since_update = (today - last_date).days
    
    if days_since_update > 7:
        print(f"ğŸ”„ å¢é‡æ›´æ–° {symbol} (è·ä¸Šæ¬¡{days_since_update}å¤©)...")
        df = fetch_new_data(symbol, days)
        if df is not None and len(df) > 0:
            # åˆå¹¶æ•°æ®å¹¶å»é‡
            combined = pd.concat([local_df, df])
            combined = combined[~combined.index.duplicated(keep='last')]
            combined = combined.sort_index()
            save_local_data(symbol, combined)
            return combined.tail(days)
        return local_df.tail(days)
    
    # æƒ…å†µ4: ä½¿ç”¨æœ¬åœ°æ•°æ®
    print(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜ {symbol} ({len(local_df)}æ¡, æ›´æ–°äº{last_date.strftime('%Y-%m-%d')})")
    return local_df.tail(days)


def batch_get_stocks(symbols: List[str], days: int = 365) -> Dict[str, pd.DataFrame]:
    """
    æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        days: å¤©æ•°
    
    Returns:
        dict: {symbol: DataFrame}
    """
    results = {}
    for sym in symbols:
        df = get_stock_data_cached(sym, days)
        if df is not None:
            results[sym] = df
    return results


def update_all_cached_data(symbols: List[str] = None):
    """
    æ›´æ–°æ‰€æœ‰ç¼“å­˜æ•°æ®
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œé»˜è®¤ä»è¡Œä¸šæ˜ å°„è¯»å–
    """
    if symbols is None:
        # ä»é»˜è®¤è‚¡ç¥¨æ± è¯»å–
        from app import INDUSTRY_STOCKS
        symbols = []
        for stocks in INDUSTRY_STOCKS.values():
            symbols.extend([s[0] for s in stocks])
        symbols = list(set(symbols))
    
    print(f"ğŸ“Š å¼€å§‹æ›´æ–° {len(symbols)} åªè‚¡ç¥¨æ•°æ®...")
    
    success = 0
    for sym in symbols:
        df = get_stock_data_cached(sym, force_refresh=True)
        if df is not None:
            success += 1
    
    print(f"âœ… æ›´æ–°å®Œæˆ: {success}/{len(symbols)}")


def get_cache_stats() -> Dict:
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    stats = {
        'total_stocks': 0,
        'total_size_mb': 0,
        'oldest_data': None,
        'newest_data': None,
        'stocks': []
    }
    
    files = [f for f in os.listdir(DATA_DIR) if f.endswith('.csv')]
    stats['total_stocks'] = len(files)
    
    for f in files:
        file_path = os.path.join(DATA_DIR, f)
        size_mb = os.path.getsize(file_path) / 1024 / 1024
        stats['total_size_mb'] += size_mb
        
        try:
            df = pd.read_csv(file_path, index_col=0, parse_dates=True)
            symbol = f.replace('.csv', '')
            first_date = df.index[0].strftime('%Y-%m-%d')
            last_date = df.index[-1].strftime('%Y-%m-%d')
            
            stats['stocks'].append({
                'symbol': symbol,
                'rows': len(df),
                'first_date': first_date,
                'last_date': last_date,
                'size_mb': round(size_mb, 2)
            })
        except:
            pass
    
    if stats['stocks']:
        stats['oldest_data'] = min(s['first_date'] for s in stats['stocks'])
        stats['newest_data'] = max(s['last_date'] for s in stats['stocks'])
    
    return stats


if __name__ == "__main__":
    # æµ‹è¯•
    print("=" * 50)
    print("è‚¡ç¥¨æ•°æ®ç®¡ç†å™¨æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•è·å–æ•°æ®
    df = get_stock_data_cached('600519')
    if df is not None:
        print(f"âœ… è·å–æˆåŠŸ: {len(df)}æ¡")
        print(f"æœ€æ–°: {df.iloc[-1]['close']}")
    
    # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
    print("\nç¼“å­˜ç»Ÿè®¡:")
    stats = get_cache_stats()
    print(f"è‚¡ç¥¨æ•°é‡: {stats['total_stocks']}")
    print(f"æ€»å¤§å°: {stats['total_size_mb']:.2f}MB")
